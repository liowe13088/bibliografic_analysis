{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93de95ea",
   "metadata": {},
   "source": [
    "# Dashapp Concept 3\n",
    "\n",
    "- after 3D viz and Denodogram (v1), with paper and keyword view (v2)\n",
    "- now develope v3 with year and keyword filter as well as frequency information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e88a4",
   "metadata": {},
   "source": [
    "# Process Flow\n",
    "\n",
    "- **1. Data**\n",
    "    - read in reduced one ds with only needed variables (generated in skript 04 at the beginning)\n",
    "- **2. Filter**\n",
    "    - filter for year\n",
    "    - filter for journal\n",
    "    - display for both frequency information to improve decision making\n",
    "- **3. Multivariate Analysis**\n",
    "    - transform data to correlation/distance matrix\n",
    "    - receive MDS (with set random state/experiment what visually is the best)\n",
    "    - receive clusters\n",
    "    - viz as it is done so far\n",
    "    - eventually include cluster statistics?\n",
    "- **4. Add paper table**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e05d2",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5c21e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T07:57:15.544676Z",
     "start_time": "2022-07-26T07:57:15.524680Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as pyo\n",
    "import plotly.express as px\n",
    "from dash import dash_table\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "from dash import State, ALL, MATCH\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster import hierarchy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import plotly.offline as pyo\n",
    "import plotly.figure_factory as ff\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import cut_tree\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc8a10a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T08:38:57.127319Z",
     "start_time": "2022-07-26T08:38:55.142545Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data_dash_2.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# generate subsets for scenario 2 and 3\n",
    "\n",
    "\n",
    "df[\"journal\"] = df[\"journal\"].str.upper()\n",
    "df[\"year\"] = [i.year for i in df[\"dt_year\"]]\n",
    "\n",
    "journals_scenario_3 = [i[0] for i in Counter(df.journal).most_common()][:50]\n",
    "\n",
    "df_scenario_2 = df\n",
    "df_scenario_3 = df[df[\"journal\"].isin(journals_scenario_3)]\n",
    "\n",
    "# for scenario 2 and 3, vatican does not provide enough data - drop therefore\n",
    "\n",
    "df_scenario_2 = df_scenario_2.drop(columns=[\"vatican\"])\n",
    "df_scenario_3 = df_scenario_3.drop(columns=[\"vatican\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd0e1d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T08:39:13.886746Z",
     "start_time": "2022-07-26T08:39:13.870911Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def hierachy_k(dist_M, k):\n",
    "    '''\n",
    "    input: dist_M n*n with 1-pearson values, k number of clusters\n",
    "    output: cluster mapping\n",
    "    '''\n",
    "\n",
    "    condensed_diss = squareform(dist_M)\n",
    "    linkage_M = linkage(condensed_diss, method=\"ward\", metric=\"pearson\")\n",
    "\n",
    "    ct = cut_tree(linkage_M, k)\n",
    "\n",
    "    return [i[0] for i in ct]\n",
    "\n",
    "def dist_func_pearson(X):\n",
    "    '''\n",
    "    equals 1-pearson\n",
    "    '''\n",
    "    return scipy.spatial.distance.pdist(X, metric=\"correlation\")\n",
    "\n",
    "def dist_func_n2(df_cooc):\n",
    "    '''\n",
    "    pearson N-2 implemntation\n",
    "    '''\n",
    "    M_corr = np.empty(shape=np.shape(df_cooc), dtype=np.float32)\n",
    "    # loop through coocurenceMatrix and calc n-2 pearson for M_corr\n",
    "    # inefficent since input and output symmetric - think late about it\n",
    "    for i,row in enumerate(np.array(df_cooc)): #row\n",
    "        for j,col in enumerate(np.array(df_cooc).T): # col\n",
    "            # extract corresponding n-2 vectors\n",
    "            if i == j:\n",
    "                M_corr[i,j] = 1\n",
    "            else:\n",
    "                x = np.delete(row,obj=[i,j])\n",
    "                y = np.delete(col,obj=[i,j])\n",
    "\n",
    "                M_corr[i,j] = np.corrcoef(x,y)[0,1]\n",
    "    return squareform(1-M_corr)\n",
    "\n",
    "def dist_func_cosine(X):\n",
    "    return scipy.spatial.distance.pdist(X, metric=\"cosine\")\n",
    "\n",
    "def dist_func_euc(X):\n",
    "    return scipy.spatial.distance.pdist(X, metric=\"euclidean\")\n",
    "\n",
    "dist_dict = {0: dist_func_pearson,1: dist_func_n2,2: dist_func_euc,3: dist_func_cosine}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72c82a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T08:40:32.701947Z",
     "start_time": "2022-07-26T08:40:32.500374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lion\\anaconda3\\envs\\env_time\\lib\\site-packages\\jupyter_dash\\jupyter_app.py:139: UserWarning:\n",
      "\n",
      "The 'environ['werkzeug.server.shutdown']' function is deprecated and will be removed in Werkzeug 2.1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "# get the options (# of clusters) for the slider in the app\n",
    "cluster_options = [int(i) for i in range(2,11)]\n",
    "\n",
    "app.layout = html.Div(className=\"row\", children=[\n",
    "\n",
    "    # Title\n",
    "    html.H1(\"Example - Biblografic Analysis Dashboard\"),\n",
    "\n",
    "    # Filter + descriptive\n",
    "    html.H2(\"I. Filter choices and descriptive statistics\"),\n",
    "\n",
    "    # filter choices\n",
    "    html.Div(children=[\n",
    "\n",
    "        # scenario choice\n",
    "        html.Div(\n",
    "            html.Div([\n",
    "                dcc.Dropdown(id=\"journal-scenario-dropdown\",\n",
    "                             clearable=False,\n",
    "                             options=[{'label': 'Scenario 2 (restricted)', 'value': 2},\n",
    "                                      {'label': 'Scenario 3 (only top journals)', 'value': 3}],\n",
    "                             value=3),\n",
    "                # to return info message\n",
    "                html.Div(id='scenario-dd-container', children=[])\n",
    "            ]), style={\"margin-right\": \"20px\"}\n",
    "        ),\n",
    "\n",
    "        # dropdown to choose year range\n",
    "        html.Div([\n",
    "\n",
    "            # start year\n",
    "            html.Div([html.H3(\"From: \"),\n",
    "                      dcc.Dropdown(id='dd-year-start',\n",
    "                                   clearable=False,\n",
    "                                   style={\"margin-left\": \"0.5em\", \"width\": \"130%\"})],\n",
    "                     style={\"display\": \"flex\"}),\n",
    "\n",
    "            html.Div([html.H3(\"Until: \"),\n",
    "                      dcc.Dropdown(id='dd-year-end',\n",
    "                                   clearable=False, style={\"margin-left\": \"0.5em\", \"width\": \"130%\"})],\n",
    "                     style={\"display\": \"flex\"})\n",
    "\n",
    "        ]),\n",
    "\n",
    "    ], style={\"width\": \"100%\", \"display\": \"flex\", \"align-items\": \"center\", \"justify-content\": \"center\"}),\n",
    "\n",
    "    # frequency visualizations\n",
    "    html.Div([\n",
    "\n",
    "        # frequ per year graph\n",
    "        dcc.Graph(id='year-freq-plot'),\n",
    "\n",
    "        # kw graph\n",
    "        html.Div(id=\"keyword-checkboxes\", children=[\n",
    "            dcc.Graph(id='kw-distri-plot')\n",
    "        ], style={\"display\": \"inline-block\"})\n",
    "    ], style={\"width\": \"100%\", \"display\": \"flex\", \"align-items\": \"center\", \"justify-content\": \"center\"}),\n",
    "\n",
    "    html.H2(\"II. Cluster and MDS Analysis\"),\n",
    "    html.Div(id=\"mds-cluster-info\"),\n",
    "\n",
    "    # distance choice\n",
    "    html.Div(children=[\n",
    "        html.H3(\"Choose distance measure here:\"),\n",
    "        dcc.Dropdown(id=\"distance-measure-dd\",\n",
    "                     clearable=False,\n",
    "                     options=[{'label': 'Pearson simple', 'value': 0},\n",
    "                              {'label': 'Pearson N-2', 'value': 1},\n",
    "                              {'label': 'Eucledean simple', 'value': 2},\n",
    "                              {'label': 'Cosine simple', 'value': 3}],\n",
    "                     value=1,\n",
    "                     style={\"margin-left\":\"0.5em\",\"width\":\"40%\",\"margin-top\":\"0.5em\"}),\n",
    "    ],style={\"display\":\"flex\"}),\n",
    "    # Cluster and MDS Visualisations\n",
    "    html.Div(children=[\n",
    "\n",
    "        # dendogram\n",
    "        dcc.Graph(id='dendogram', style={\"display\": \"inline-block\"}),\n",
    "\n",
    "        # slider number clusters\n",
    "        html.Div([\n",
    "            dcc.Slider(\n",
    "                id='cluster-slider',\n",
    "                min=min(cluster_options),\n",
    "                max=max(cluster_options),\n",
    "                value=max(cluster_options),\n",
    "                marks={str(n): str(n) for n in cluster_options},\n",
    "                step=None,\n",
    "                vertical=True,\n",
    "                verticalHeight=600,\n",
    "            )\n",
    "        ], style={\"display\": \"inline-block\"}),\n",
    "\n",
    "        # 3d viz\n",
    "        html.Div([\n",
    "            dcc.Graph(id='cluster-3d-graph',\n",
    "                      style={\"width\": '80vh', \"height\": \"80vh\",\n",
    "                             \"display\": \"inline-block\"}),\n",
    "            html.Div(id='3d-graph-container')\n",
    "        ])\n",
    "\n",
    "    ], style={\"width\": \"100%\", \"display\": \"flex\", \"align-items\": \"center\", \"justify-content\": \"center\"}),\n",
    "\n",
    "    html.Br(),\n",
    "\n",
    "    # tables\n",
    "\n",
    "    html.Div([\n",
    "\n",
    "        # cluster\n",
    "        html.Div([\n",
    "            html.H4(\"Current keywords within each cluster:\"),\n",
    "            html.Div([\n",
    "                html.Div(id='cluster-table')\n",
    "            ], style={\"width\": \"100%\", \"display\": \"flex\", \"align-items\": \"center\", \"justify-content\": \"center\"})\n",
    "        ], style={\"width\": \"100%\", \"display\": \"inline-block\"}),\n",
    "\n",
    "        # papers\n",
    "        html.Div([\n",
    "            html.H4(\"Papers contained in current filter-settings:\"),\n",
    "            dcc.RadioItems(\n",
    "                options = [{'label': 'Read filter_query', 'value': 'read'}, {'label': 'Write to filter_query', 'value': 'write'}],\n",
    "                value = 'read',\n",
    "                id='filter-query-read-write',\n",
    "            ),\n",
    "\n",
    "            html.Br(),\n",
    "\n",
    "            dcc.Input(id='filter-query-input', placeholder='Enter filter query'),\n",
    "\n",
    "            html.Div(id='filter-query-output'),\n",
    "\n",
    "            html.Hr(),\n",
    "\n",
    "            html.Div([\n",
    "\n",
    "                dash_table.DataTable(id=\"docs-table\",\n",
    "                     export_columns=\"visible\",\n",
    "                     export_format=\"xlsx\",\n",
    "                     export_headers=\"display\",\n",
    "                     sort_action=\"native\",\n",
    "                     filter_action=\"native\",\n",
    "                     sort_mode=\"multi\",\n",
    "                     style_data={'whiteSpace': 'normal',\n",
    "                                 'height': 'auto',\n",
    "                                 'lineHeight': '10px',\n",
    "                                 'overflowX': 'auto'},\n",
    "                     style_cell_conditional=[\n",
    "                         {'if': {'column_id': 'year'}, 'width': '5%'},\n",
    "                         {'if': {'column_id': 'author'}, 'width': '25%'},\n",
    "                         {'if': {'column_id': 'title'}, 'width': '35%'},\n",
    "                         {'if': {'column_id': 'times-cited'}, 'width': '5%'},\n",
    "                         {'if': {'column_id': 'journal'}, 'width': '10%'},\n",
    "                         {'if': {'column_id': 'keywords'}, 'width': '15%'}\n",
    "                     ],\n",
    "                     style_cell={\"textAlign\": 'left'},\n",
    "                     style_as_list_view=True\n",
    "                     ),\n",
    "\n",
    "\n",
    "            ], style={\"width\": \"100%\", \"display\": \"flex\", \"align-items\": \"center\", \"justify-content\": \"center\"})\n",
    "\n",
    "\n",
    "        ], style={\"width\": \"100%\", \"display\": \"inline-block\"})\n",
    "\n",
    "    ]),\n",
    "\n",
    "    dcc.Store(id='scenario_data'),\n",
    "    dcc.Store(id='final_data'),\n",
    "    dcc.Store(id='final_dummies'),\n",
    "    dcc.Store(id='kw_cluster_data')\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('scenario_data', 'data'),\n",
    "    Input('journal-scenario-dropdown', 'value'))\n",
    "def update_scenario(scenario):\n",
    "    # data prep - needs to happen after every filter adjustment in the dashapp\n",
    "\n",
    "    # 1 filter for scenario\n",
    "\n",
    "    df[\"journal\"] = df[\"journal\"].str.upper()\n",
    "\n",
    "    if scenario == 3:\n",
    "        df_scenario = df_scenario_3\n",
    "    elif scenario == 2:\n",
    "        df_scenario = df_scenario_2\n",
    "\n",
    "    journal_message = f\"Scenario {scenario}\"\n",
    "\n",
    "    return df_scenario.to_json(orient='split')\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('dd-year-start', 'options'),\n",
    "    Output('dd-year-start', 'value'),\n",
    "    Input('scenario_data', 'data'))\n",
    "def update_year_start(data_scenario):\n",
    "    df = pd.read_json(data_scenario, orient='split')\n",
    "\n",
    "    min_year = int(min(df[\"year\"]))\n",
    "    max_year = int(max(df[\"year\"]))\n",
    "\n",
    "    return [{'label': i, 'value': i} for i in range(min_year, max_year + 1)], min_year\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('dd-year-end', 'options'),\n",
    "    Output('dd-year-end', 'value'),\n",
    "    Input('dd-year-start', 'value'),\n",
    "    Input('scenario_data', 'data'))\n",
    "def update_year_end(start_value, data_scenario):\n",
    "    df = pd.read_json(data_scenario, orient='split')\n",
    "\n",
    "    min_year = start_value\n",
    "    max_year = int(max(df[\"year\"]))\n",
    "\n",
    "    return [{'label': i, 'value': i} for i in range(min_year, max_year + 1)], max_year\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('final_data', 'data'),\n",
    "    Output('final_dummies', 'data'),\n",
    "    Output('scenario-dd-container', 'children'),\n",
    "    Input('scenario_data', 'data'),\n",
    "    Input('dd-year-start', 'value'),\n",
    "    Input('dd-year-end', 'value'))\n",
    "def update_data_year(data_scenario, start_year, end_year):\n",
    "    df = pd.read_json(data_scenario, orient='split')\n",
    "\n",
    "    # filter based on year values\n",
    "    df_final = df[(df[\"year\"] <= end_year) & (df[\"year\"] >= start_year)]\n",
    "\n",
    "    # get base info from df\n",
    "    n_docs = len(df_final)  # number of papers in filtered ds\n",
    "    df_dummy = df_final.iloc[:, 4:-2]  # only dummy variables (keywords)\n",
    "    max_kw = len(df_dummy.columns)  # max number of keywords\n",
    "\n",
    "    # drop keywords with zero occurences in current filter setting\n",
    "    vec_drop = list(df_dummy.sum(axis=0) > 0)\n",
    "\n",
    "    # apply to dummy df and df with all variables\n",
    "    df_dummy = df_dummy.loc[:, vec_drop]\n",
    "    true_kw = len(df_dummy.columns)  # max number of keywords\n",
    "    df_final = df_final.loc[:, [True, True, True, True] + vec_drop + [True, True]]\n",
    "\n",
    "    # put together info message\n",
    "    message = dcc.Markdown(\n",
    "        f\"Number of papers included in analysis: {n_docs} \\nNumber of possible keywords: {max_kw} \\nNumber of keywords after filtering: {true_kw}\",\n",
    "        style={\"white-space\": \"pre\"})\n",
    "\n",
    "    return df_final.to_json(orient='split'), df_dummy.to_json(orient='split'), message\n",
    "\n",
    "\n",
    "### number of papers per year (graph/info)\n",
    "\n",
    "@app.callback(\n",
    "    Output('year-freq-plot', 'figure'),\n",
    "    Input('final_data', 'data'))\n",
    "def yearly_papers(df):\n",
    "    data = pd.read_json(df, orient='split')\n",
    "    years_list = data.loc[:, \"year\"]\n",
    "    countery = Counter(years_list)\n",
    "    countery_data = sorted(countery.items())\n",
    "\n",
    "    updatemenus = [\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            direction=\"left\",\n",
    "            x=1,\n",
    "            y=1.2,\n",
    "            buttons=list([\n",
    "                dict(\n",
    "                    args=[{'yaxis.type': 'linear'}],\n",
    "                    label=\"Linear\",\n",
    "                    method=\"relayout\"\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[{'yaxis.type': 'log'}],\n",
    "                    label=\"Log\",\n",
    "                    method=\"relayout\"\n",
    "                )\n",
    "            ])\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    p_fig = px.bar(countery_data, x=0, y=1, title=\"Number of papers published per year\")\n",
    "\n",
    "    p_fig.update_layout(yaxis_title=None, xaxis_title=None,\n",
    "                        width=800, height=400, updatemenus=updatemenus)\n",
    "\n",
    "    return p_fig\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('kw-distri-plot', 'figure'),\n",
    "    Input('final_dummies', 'data'))\n",
    "def update_kw_figure(dt_words):\n",
    "    # frequency distribution keywords plot\n",
    "\n",
    "    dt_words = pd.read_json(dt_words, orient='split')\n",
    "    kw_distri = dt_words.sum(axis=0).sort_values(ascending=True)\n",
    "\n",
    "    updatemenus = [\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            direction=\"left\",\n",
    "            x=1,\n",
    "            y=1.25,\n",
    "            buttons=list([\n",
    "                dict(\n",
    "                    args=[{'yaxis.type': 'linear'}],\n",
    "                    label=\"Linear\",\n",
    "                    method=\"relayout\"\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[{'yaxis.type': 'log'}],\n",
    "                    label=\"Log\",\n",
    "                    method=\"relayout\"\n",
    "                )\n",
    "            ])\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    kw_fig = px.bar(kw_distri, title=\"Number of papers per keyword\")\n",
    "    kw_fig.update_xaxes(tickangle=-45)\n",
    "    kw_fig.update_layout(width=800, height=400, showlegend=False,\n",
    "                         yaxis_title=None, xaxis_title=None, updatemenus=updatemenus)\n",
    "    return kw_fig\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('cluster-3d-graph', 'figure'),\n",
    "    Output('dendogram', 'figure'),\n",
    "    Output('mds-cluster-info', 'children'),\n",
    "    Output('cluster-table', 'children'),\n",
    "    Output('3d-graph-container', 'children'),\n",
    "    Output('kw_cluster_data','data'),\n",
    "    Input('cluster-slider', 'value'),\n",
    "    Input('final_dummies', 'data'),\n",
    "    Input('distance-measure-dd','value')\n",
    ")\n",
    "def update_cluster_figure_table(n_cluster, data,distance_function_value):\n",
    "    # diagonals become 0 - we want to ignore the cells for the same keywords\n",
    "    dt_words = pd.read_json(data, orient='split')\n",
    "    n_docs = len(dt_words)\n",
    "\n",
    "    M_cooc = dt_words.T.dot(dt_words)\n",
    "    np.fill_diagonal(M_cooc.values, 0)\n",
    "\n",
    "    # get correlation based on that\n",
    "    # calc distance!-------------------------------\n",
    "    # set distance fucntion\n",
    "    dist_func = dist_dict[distance_function_value]\n",
    "\n",
    "    M_dist = squareform(dist_func(M_cooc))\n",
    "    order_kw = M_cooc.columns\n",
    "    #-----------------------------------------------\n",
    "    checknan = str(np.isnan(M_dist).any())\n",
    "\n",
    "    n_keywords = len(order_kw)\n",
    "\n",
    "    if checknan == str(False):\n",
    "        message = f\"dense enough data for MDS/Clustering. Using {n_keywords} out of 36 keywords.\\n {n_docs} papers.\"\n",
    "\n",
    "        embedding = MDS(n_components=3, dissimilarity='precomputed', random_state=3)\n",
    "        x_transformed = embedding.fit_transform(M_dist)\n",
    "\n",
    "        # stress\n",
    "        stress = embedding.stress_\n",
    "        stress1 = np.sqrt(stress / (0.5 * np.sum((pd.DataFrame(M_dist)).values ** 2)))\n",
    "        message_stress = f\"Kruskal's Stress : {stress1}  [Poor > 0.2 > Fair > 0.1 > Good > 0.05 > Excellent > 0.025 > Perfect > 0.0]\"\n",
    "\n",
    "        ## Cluster\n",
    "        cl = hierachy_k(M_dist, n_cluster)\n",
    "        viz_df = pd.DataFrame({\"kw\": order_kw, \"cluster\": cl, \"dim1\": x_transformed[:, 0],\n",
    "                               \"dim2\": x_transformed[:, 1], \"dim3\": x_transformed[:, 2]})\n",
    "\n",
    "        viz_df[\"cluster\"] = viz_df[\"cluster\"]+1\n",
    "        viz_df[\"cluster\"] = viz_df[\"cluster\"].astype(\"string\")\n",
    "\n",
    "        fig = px.scatter_3d(viz_df, x='dim1', y='dim2', z='dim3', text=\"kw\", color=\"cluster\",\n",
    "                            color_discrete_sequence=px.colors.qualitative.Safe)\n",
    "\n",
    "        dendo = ff.create_dendrogram(X=M_cooc, labels=order_kw,\n",
    "                                     orientation=\"left\",\n",
    "                                     distfun=dist_func,\n",
    "                                     linkagefun=lambda x: sch.linkage(x, \"ward\"))\n",
    "\n",
    "        dendo.update_layout(width=500, height=700)\n",
    "\n",
    "        fig.update_layout(transition_duration=500, legend_title_text=\"Cluster\")\n",
    "\n",
    "        # update table\n",
    "\n",
    "        df_table = viz_df.loc[:, [\"kw\", \"cluster\"]]\n",
    "\n",
    "        c_table = pd.DataFrame(\n",
    "            df_table.pivot_table(values='kw', index=df_table.index, columns='cluster', aggfunc='first'))\n",
    "        c_table = c_table.apply(lambda x: pd.Series(x.dropna().values))\n",
    "\n",
    "        table = dash_table.DataTable(id=\"c-table\",\n",
    "                                     columns=[{\"name\": \"cluster \" + str(i), \"id\": str(i)} for i in c_table.columns],\n",
    "                                     data=c_table.to_dict(\"records\"),\n",
    "                                     style_table={\"overflowX\": \"auto\"},\n",
    "                                     style_cell={'minWidth': '100px', 'width': '100px', 'maxWidth': '100px',\n",
    "                                                 'whiteSpace': 'normal',\n",
    "                                                 'textAlign': 'left'},\n",
    "\n",
    "                                     tooltip_data=[\n",
    "                                         {\n",
    "                                             column: {'value': str(value), 'type': 'markdown'}\n",
    "                                             for column, value in row.items()\n",
    "                                         } for row in c_table.to_dict('records')\n",
    "                                     ],\n",
    "                                     tooltip_duration=None,\n",
    "                                     style_as_list_view=False)\n",
    "\n",
    "        return fig, dendo, message, table, message_stress, df_table.to_json(orient='split')\n",
    "\n",
    "    else:\n",
    "\n",
    "        message = f\"too sparse data for MDS/Clustering!\"\n",
    "        ## MDS\n",
    "\n",
    "        return {}, {}, message, {}, {}, {}\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('docs-table', 'data'),\n",
    "    Output('docs-table', 'columns'),\n",
    "    Input('final_data', 'data'),\n",
    "    Input('kw_cluster_data','data'))\n",
    "def update_paper_table(data,kw_cluster):\n",
    "    # make keyword column, for each papaer containing all related keywords\n",
    "\n",
    "    df_table = pd.read_json(data, orient='split')\n",
    "    \n",
    "    df_table[\"id\"] = [i for i in range(len(df_table))]\n",
    "    df_table.set_index('id', inplace=True)\n",
    "\n",
    "    dummies = df_table.iloc[:, 4:-2]\n",
    "\n",
    "    df_temp = dummies[dummies == 1].stack().reset_index()\n",
    "    df_temp = df_temp.groupby([\"id\"])[\"level_1\"].apply(', '.join).reset_index()\n",
    "\n",
    "    df_table[\"keywords\"] = df_temp[\"level_1\"]\n",
    "    \n",
    "    # add cluster column based on keywords\n",
    "    df_kw_cluster = pd.read_json(kw_cluster, orient='split')\n",
    "    \n",
    "    \n",
    "    def map_kw_to_cluster(kw_string):\n",
    "        cl_list = []\n",
    "        kw_list = kw_string.replace(\" \",\"\").split(\",\")\n",
    "        for kw in kw_list:\n",
    "            cl_list.append(kw_dict[kw])\n",
    "        return [str(i) for i in cl_list]\n",
    "    \n",
    "    kw_dict = {k:v for k,v in zip(df_kw_cluster[\"kw\"],df_kw_cluster[\"cluster\"])}\n",
    "    \n",
    "    #cl_col = list(df_table.loc[:,\"keywords\"].copy())\n",
    "    #cl_col = [\",\".join(map_kw_to_cluster(i)) for i in df_table[\"keywords\"]]\n",
    "    cl_col = [\",\".join(map_kw_to_cluster(i)) for i in df_table[\"keywords\"]]\n",
    "    \n",
    "    \n",
    "    df_table.loc[:,\"cluster\"] = cl_col\n",
    "    \n",
    "    \n",
    "    #-----------------------\n",
    "    \n",
    "    \n",
    "    pd_table = df_table.loc[:, [\"year\",\"times-cited\", \"journal\", \"title\", \"author\", \"keywords\",\"cluster\"]]\n",
    "    pd_table[\"year\"] = pd.to_numeric(pd_table[\"year\"])\n",
    "\n",
    "\n",
    "    columns=[{\"name\": i, \"id\": i} for i in pd_table.columns]\n",
    "    data=pd_table.to_dict(\"records\")\n",
    "\n",
    "    return data,columns\n",
    "\n",
    "\n",
    "### custom filter system docs table\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('filter-query-input', 'style'),\n",
    "    Output('filter-query-output', 'style'),\n",
    "    Input('filter-query-read-write', 'value')\n",
    ")\n",
    "def query_input_output(val):\n",
    "    input_style = {'width': '100%'}\n",
    "    output_style = {}\n",
    "    if val == 'read':\n",
    "        input_style.update(display='none')\n",
    "        output_style.update(display='inline-block')\n",
    "    else:\n",
    "        input_style.update(display='inline-block')\n",
    "        output_style.update(display='none')\n",
    "    return input_style, output_style\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('docs-table', 'filter_query'),\n",
    "    Input('filter-query-input', 'value')\n",
    ")\n",
    "def write_query(query):\n",
    "    if query is None:\n",
    "        return ''\n",
    "    return query\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('filter-query-output', 'children'),\n",
    "    Input('docs-table', 'filter_query')\n",
    ")\n",
    "def read_query(query):\n",
    "    if query is None:\n",
    "        return \"No filter query\"\n",
    "    return dcc.Markdown('`filter_query = \"{}\"`'.format(query))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n",
    "    # app.run_server(mode='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a4aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa8dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7666af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ccfeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9456a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf4418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11018fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c38945b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a137c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486182e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
